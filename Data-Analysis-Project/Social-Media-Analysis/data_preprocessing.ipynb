{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification # for tweet sentiment analysis\n",
    "from deep_translator import GoogleTranslator # translate location\n",
    "from geopy.geocoders import Nominatim # get country for city name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('location.isnull()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling all the missing values with \"Not Specified\" from location column\n",
    "df['location'].fillna(\"not_specified\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']) # convert into datetime format\n",
    "\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month_name'] = df['date'].dt.month_name()\n",
    "df['month_day'] = df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_date'] = [d.date() for d in df['date']]\n",
    "\n",
    "df['time'] = [d.time() for d in df['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('date',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts city name, state into country name\n",
    "geolocator = Nominatim(user_agent = \"http\")\n",
    "loc = geolocator.geocode('Nigeria')\n",
    "print(loc.address.split(\",\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_tweet = GoogleTranslator(source='auto', target='en')\n",
    "translate_tweet.translate(\"대한민국 서울\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(place):\n",
    "    '''\n",
    "    returns country name given city but cities in country like saudi arabia, china output like \"대한민국 서울\"\n",
    "    so we need to translate in the end.\n",
    "    '''\n",
    "    try:\n",
    "        loc = geolocator.geocode(place.lower())\n",
    "        address = loc.address.split(\",\")[-1].strip()\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "    return translate_tweet.translate(address) # may contain some chinese words like \"北京\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_link(tweet):\n",
    "    '''\n",
    "    replace all the link with \"http\" for sentiment analysis\n",
    "    '''\n",
    "    pattern = r'((www|http\\:\\/\\/|https\\:\\/\\/)?.[\\w]*.(com|co))+(\\/?[\\w]?)*'\n",
    "    match = re.compile(pattern)\n",
    "    return match.sub(\"http\", tweet)\n",
    "    \n",
    "def format_text(tweet):\n",
    "    '''\n",
    "    replace all the \\n with space from the tweet\n",
    "    '''\n",
    "    pattern = r'\\n'\n",
    "    match = re.compile(pattern)\n",
    "    return match.sub(\" \", tweet)\n",
    "\n",
    "def format_mention(tweet):\n",
    "    '''\n",
    "    replace all the @username mention to @user for sentiment analysis\n",
    "    '''\n",
    "    pattern = r'@[\\w]+'\n",
    "    match = re.compile(pattern)\n",
    "    return match.sub(\"@user\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_country(\"fresno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert anything which is not posted from webapp, iphone, android, ipad etc. to social media management platform\n",
    "df['source'] = np.where((df['source'] != \"Twitter Web App\") & \n",
    "                        (df['source'] != \"Twitter for iPhone\") & \n",
    "                        (df['source'] != \"Twitter for Android\") & \n",
    "                        (df['source'] != \"Twitter for iPad\") & \n",
    "                        (df['source'] != \"Twitter Media Studio\") & \n",
    "                        (df['source'] != \"Twitter for Advertisers\"), \n",
    "                        \"Social Media Management Platform\", df['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = df['content'].apply(lambda x: format_text(format_link(format_mention(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model for tweet analysis\n",
    "roberta = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(roberta)\n",
    "labels = [ \"Negative\", \"Neutral\", \"Positive\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = format_link(format_mention(format_text(df.cleaned_tweet[990])))\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='tf')\n",
    "    output = model(encoded_tweet, training=False).logits\n",
    "    return np.argmax(tf.nn.softmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = (df['cleaned_tweet'].apply(lambda x: labels[get_sentiment(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'new_column':'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
